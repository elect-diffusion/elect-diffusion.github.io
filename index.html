<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing">
  <meta property="og:title" content="Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing"/>
  <meta property="og:description" content="Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing">
  <meta name="twitter:description" content="Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>
    Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing (ELECT)
  </title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Joowon Kim
                </a>
                <sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Ziseok Lee
                </a>
                <sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Donghyeon Cho
                </a>,
              </span>
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Sanghyun Jo
                </a>,
              </span>
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Yeonsung Jung
                </a>,
              </span>
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Kyungsu Kim
                </a>
                <sup>†</sup>,
              </span>
              <span class="author-block">
                <a href="https://elect-diffusion.github.io/" target="_blank">
                  Eunho Yang
                </a>
                <sup>†</sup>,
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">KAIST, Seoul National University, OGQ<br />ICCV 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2504.13490.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                        </a>
                      </span>


                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/Joow0n-Kim/ELECT" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                        </a>
                      </span>

                      <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2504.13490" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                        </a>
                      </span>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </section>


        <!-- Teaser video-->
        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img 
                src="static/images/ELECT_intro.png"
              />
              <div class="content has-text-justified">
                Instruction-guided image editing models are highly influenced by the noise seed. To address this issue, we propose a unique candidate selection method (ELECT), which is successfully selects the best seed for background consistency while maintaining the editability of the base model. We propose Background Inconsistency Score (BIS) that quantifies the degree of unintended background changes in an edited image, measuring relatively how well the background is preserved compared to other candidates in a self-supervised manner.
              </div>
            </div>
          </div>
        </section>
        <!-- End teaser video -->

        <!-- Paper abstract -->
        <section class="section hero is-light">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                  <p>
                    Despite recent advances in diffusion models, achieving reliable image generation and editing results remains challenging due to the inherent diversity induced by stochastic noise in the sampling process. Particularly, instruction-guided image editing with diffusion models offers user-friendly editing capabilities, yet editing failures, such as background distortion, frequently occur across different attempts. Users often resort to trial and error, adjusting seeds or prompts to achieve satisfactory results, which is inefficient.
                    While seed selection methods exist for Text-to-Image (T2I) generation, they depend on external verifiers, limiting their applicability, and evaluating multiple seeds increases computational complexity, reducing practicality.
                    To address this, we first establish a new multiple-seed-based image editing baseline using background consistency scores, achieving Best-of-N performance without supervision. Building on this, we introduce ELECT (Early-timestep Latent Evaluation for Candidate selecTion), a zero-shot framework that selects reliable seeds by estimating background mismatches at early diffusion timesteps, identfying the seed that retains the background while modifying only the foreground. ELECT ranks seed candidates by a background inconsistency score, filtering unsuitable samples early based on background consistency while fully preserving editability. Beyond standalone seed selection, ELECT integrates into instruction-guided editing pipelines and extends to Multimodal Large-Language Models (MLLMs) for joint seed + prompt selection, further improving results when seed selection alone is insufficient. Experiments show that ELECT reduces computational costs (by 41% on average and up to 61%) while improving background consistency and instruction adherence, achieving around 40% success rates in previously failed cases—without any external supervision or training.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </section>
        <!-- End paper abstract -->


        <section class="section hero">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column is-full">
                <h2 class="title is-3">Method</h2>
                <img
                  src="static/images/ELECT_pipeline.jpg"
                  alt="MY ALT TEXT"
                />
                <div class="content has-text-justified">
                  <p>
                    We introduce ELECT, a model-agnostic and efficient framework for selecting high-quality edited images from diffusion-based editing pipelines. ELECT stops denoising early and selects the best candidate based on background consistency. Selection is driven by the Background Inconsistency Score (BIS): a relative metric that penalizes unintended background changes while ignoring the intended foreground edit, ensuring the chosen candidate delivers the cleanest, most consistent result.
                  </p>
                </div>
                <img
                  src="static/images/ELECT_alg.png"
                  alt="MY ALT TEXT"
                  style="max-width:50%; height:auto; display:block; margin:0 auto;"
                />
                <div class="content has-text-justified">
                  <p>
                    ELECT halts all seeds at t<sub>stop</sub>, ranks them with BIS, and denoises only the top seed, preserving quality while sharply reducing compute.
                  </p>
                </div>
                <img
                  src="static/images/fig_prompt_variance.png"
                  alt="MY ALT TEXT"
                />
                <div class="content has-text-justified">
                  <p>
                    ELECT extends to prompt selection by incorporating MLLMs, improving editing reliability when seed selection alone is insufficient.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </section>

        <!-- Image carousel -->
        <section class="hero is-small is-light">
          <div class="hero-body">
              <div class="container is-max-desktop">
                <div class="columns is-centered">
                  <div class="column is-full">
                    <h2 class="title is-3">Experiment</h2>
                  </div>
                </div>
              <img
                  src="static/images/Efficiency.png"
                  alt="MY ALT TEXT"
                  style="max-width:80%; height:auto; display:block; margin:0 auto;"
              />
              <div class="content has-text-justified">
                <p>
                  We match cases with almost identical background MSE; even then, ELECT achieves slightly better quality. Its computational cost (NFE) grows only with the chosen seed count and early-stop step.
                </p>
              </div>
              <div id="results-carousel" class="carousel results-carousel">
              <div class="item">
                <!-- Your image here -->
                <img src="static/images/PIE-supple_InstructPix2Pix.png" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Dataset: PIE-Bench, Model: InstructPix2Pix
                </h2>
              </div>
              <div class="item">
                <!-- Your image here -->
                <img src="static/images/PIE-supple_MagicBrush.png" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Dataset: PIE-Bench, Model: MagicBrush
                </h2>
              </div>
              <div class="item">
                <!-- Your image here -->
                <img src="static/images/PIE-supple_InstructDiffusion.png" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Dataset: PIE-Bench, Model: InstructDiffusion
                </h2>
              </div>
              <div class="item">
                <!-- Your image here -->
                <img src="static/images/PIE-supple_MGIE.png" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Dataset: PIE-Bench, Model: MGIE
                </h2>
              </div>
              <div class="item">
                <!-- Your image here -->
                <img src="static/images/PIE-supple_UltraEdit.png" alt="MY ALT TEXT"/>
                <h2 class="subtitle has-text-centered">
                  Dataset: PIE-Bench, Model: UltraEdit
                </h2>
              </div>
            </div>
          </div>
        </div>
        </section>
        <!-- End image carousel -->




<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@InProceedings{kim2025early,
        title={Early timestep zero-shot candidate selection for instruction-guided image editing},
        author={Kim, Joowon and Lee, Ziseok and Cho, Donghyeon and Jo, Sanghyun and Jung, Yeonsung and Kim, Kyungsu and Yang, Eunho},
        booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
